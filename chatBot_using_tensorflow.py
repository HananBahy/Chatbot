# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function
""" this ChatBot is made from make changes on nural machine translation with attention  """

"""nmt_with_attention.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb

##### Copyright 2018 The TensorFlow Authors.

Licensed under the Apache License, Version 2.0 (the "License").

# Neural Machine Translation with Attention

"""



# Import TensorFlow >= 1.10 and enable eager execution
import tensorflow as tf

tf.enable_eager_execution()

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
#from tensorflow.python.keras.layers import Bidirectional
from help_functions import clean_text , gru , lstm ,pretrained_embeddings,blstm , lstmb
from keras.layers import Dense ,LSTM ,Lambda,Concatenate,TimeDistributed ,Embedding
from keras.initializers import Constant
import keras as k
import unicodedata
import re
import numpy as np
import os
import time
import keras.backend as K
if len(K.tensorflow_backend._get_available_gpus()) > 0:
  from keras.layers import CuDNNLSTM as LSTM
  from keras.layers import CuDNNGRU as GRU

print(tf.__version__)
##################################preprocessing Dataset#########################
"""##  prepare the dataset 

1. Clean the sentences by removing special characters and convert shorthands to original format ex: i'm ---> i am.
2. Add a *start* and *end* token to each sentence.
3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).
4. Pad each sentence to a maximum length.
5. finally create dataset using tf.data

we make above work using set of functions and custom class  where each function use above elemented functions as following:
"""


def preprocess_sentence(w):
    w = w.lower().strip()
    # creating a space between a word and the punctuation following it
    # eg: "he is a boy." => "he is a boy ." 
    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation
    w = re.sub(r"([?.!,¿])", r" \1 ", w)
    w = re.sub(r'[" "]+', " ", w)
    
    # replacing everything with space except (a-z, A-Z, ".", "?", "!", ",") and 0-9 as our data has dates
    w = re.sub(r"[^0-9a-zA-Z?.!,¿]+", " ", w)
    #w = re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,]", "",w)   #and 0-9
    w = clean_text(w)     #used to convert shorthands to original format
    w = w.rstrip().strip()
    
    # adding a start and an end token to the sentence
    # so that the model know when to start and stop predicting.
    w = '<start> ' + w + ' <end>'
    return w

# 1. Remove the accents
# 2. Clean the sentences
# 3. Get btain question-Answer pairs in the format:[ [Question1 , Answer1] ,[Question2,Answer2],......]
# 4. Return Questions , Answers where Questions=[Question1 , Question2 ,....]  , Answers=[Answer1,Answer2,.....]

def create_dataset(file_path,num_samples):
    #each line in file in this form  "Question \t  Answer"
    lines = open(file_path, encoding='UTF-8').read().strip().split('\n')

    Q_A_pairs = [[preprocess_sentence(sent) for sent in l.split('\t')]  for l in lines[:num_samples]]  
        #Q_A_pairs=[[Q1,A1],[Q2,A2],...]

    Questions , Answers = [list(item) for item in zip(*Q_A_pairs)]

    return Questions , Answers

#Questions , Answers =  create_dataset(file_path,num_samples)
#print(Questions[0])
#print(Answers[0])


# This class creates a word -> index mapping (e.g,. "dad" -> 5) and vice-versa 
# (e.g., 5 -> "dad") for whole vocabulary in questions and answers as they are in the same language
class VocabIndex():
  def __init__(self, data):
    self.data = data        #all sentences in questions and answers
    self.word2idx = {}
    self.idx2word = {}
    self.vocab = set()
    
    self.create_index()
    
  def create_index(self):
    for phrase in self.data:
      self.vocab.update(phrase.split(' '))     #set of unique tokens
    
    self.vocab = sorted(self.vocab)
    
    self.word2idx['<pad>'] = 0    #we use 0 to padding the sentence after converted to sequence of integer numbers each number is 
                                    #index of word in word2indx
    for index, word in enumerate(self.vocab):
      self.word2idx[word] = index + 1    #index+1 as index 0 is reversed before for <pad>
    
    for word, index in self.word2idx.items():
      self.idx2word[index] = word

## find max input seq(question) length  or max output seq (Answer)
def max_length(tensor):
    return max(len(t) for t in tensor)


def load_dataset(file_path , num_samples):
    # creating cleaned input, output pairs
    Questions , Answers = create_dataset(file_path,num_samples)
    print("number of samples in data : " ,len(Questions))
    # index language using the class defined above    
    VocabInd = VocabIndex(Questions+Answers)     #data = Questions and answers to make dictionay for all words used in our data corpus
    
    # Vectorize the input and target data
    # Question sentences , each sentence as sequence of integers
    input_tensor = [[VocabInd.word2idx[s] for s in Q.split(' ')] for Q in Questions]
    
    # Answer sentences , each sentence as sequence of integers
    target_tensor = [[VocabInd.word2idx[s] for s in A.split(' ')] for A in Answers]
    
    # Calculate max_length of input and output tensor
    # Here, we'll set those to the longest sentence in the dataset
    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)
    
    # Padding the input and output tensor to the maximum length
    # #pad each sequence with length <max_length by zeros after it (padding='post')
    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, 
                                                                 maxlen=max_length_inp,
                                                                 padding='post')
    
    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, 
                                                                  maxlen=max_length_tar, 
                                                                  padding='post')
    
    return input_tensor, target_tensor, VocabInd, max_length_inp, max_length_tar


"""### Limit the size of the dataset to experiment faster (optional)

Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):
"""

# Try experimenting with the size of that dataset
num_examples = 10000
Data_file_path = 'datasets/Q_A_pairs8.txt'        ##################
input_tensor, target_tensor, VocabInd, max_length_inp, max_length_targ = load_dataset(Data_file_path,num_examples)

# Creating training and validation sets using an 80-20 split
input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)

# Show length
print('num. of training samples : ',input_tensor_train)
print('num. of validation  samples : ',input_tensor_val)
#show shape of input and target
print("encoder_data.shape:", input_tensor_train.shape)           
print("encoder_data[0]:", input_tensor_train[0])

print("decoder_data.shape:", target_tensor_train.shape)           
print("decoderr_data[0]:", target_tensor_train[0])

"""### Create a tf.data dataset for training"""

BUFFER_SIZE = len(input_tensor_train)
BATCH_SIZE = 3 # Batch size for training.
N_BATCH = BUFFER_SIZE//BATCH_SIZE

EMBEDDING_DIM = 50   #length of word vector
#units = 1024
units=512
units1=LATENT_DIM = units//2        #in case of bidirectional LSTM in encoder , no.units of one direction must equal 
                                       #==.5 no.units in decoder
                                  #but in uni directional LSTM in encoder , then no.units in encoder = no.units in decoder
units2=LATENT_DIM_DECODER = units # idea: make it different to ensure things all fit together properly!
vocab_size = len(VocabInd.word2idx)
print("VOCAB_SIZE: " ,vocab_size)

dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)
dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)

#check
example_input_batch, example_target_batch = next(iter(dataset))
print("input_batch_shape : " ,example_input_batch.shape)
print("output_batch_shape : ", example_target_batch.shape)
#######################################################################################################################################
         ################# Encoder-Decoder model  with attention ################
"""
The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* 
        and the encoder hidden state of shape *(batch_size, hidden_size)*. 

Here are the equations that are implemented:

<img src="https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg" alt="attention equation 0" width="800">
<img src="https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg" alt="attention equation 1" width="800">

We're using *Bahdanau attention*. Lets decide on notation before writing the simplified form:

* FC = Fully connected (dense) layer
* EO = Encoder output
* H = hidden state
* X = input to the decoder

And the pseudo-code:

* `score = FC(tanh(FC(EO) + FC(H)))`
* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.
* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.
* `embedding output` = The input to the decoder X is passed through an embedding layer.
* `merged vector = concat(embedding output, context vector)`
* This merged vector is then given to the GRU
  
The shapes of all the vectors at each step have been specified in the comments in the code:
"""
          #1-Encoder
class Encoder(tf.keras.Model):
  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz,embedding_matrix):
    super(Encoder, self).__init__()
    self.batch_sz = batch_sz
    self.enc_units = enc_units
    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,weights=[embedding_matrix],
                                                                        input_length=max_length_inp,trainable=False)
    #self.W = tf.constant(embedding_matrix, name="W")
    self.embedding2 = Embedding(vocab_size, embedding_dim)#,weights=[embedding_matrix],
                                                        #input_length=max_length_inp,
                                                        #trainable=False) ######
    
    self.lstm = lstm(self.enc_units)
    self.lstmb = lstm(self.enc_units)
    #self.lstm2 = lstm(self.enc_units)
    #self.lstmb2 = lstm(self.enc_units)
    self.lstm2 = LSTM(self.enc_units,return_sequences=True, return_state=True)
    self.lstmb2 = LSTM(self.enc_units,return_sequences=True, return_state=True,go_backwards=True)
    self.Bidirectional = tf.keras.layers.Bidirectional(self.lstm,merge_mode='concat')
    
  def call(self, x, hidden):
    print(x.shape)
    x = self.embedding2(x)
    print(x.shape)
    output_f, state_h_f ,state_c_f= self.lstm2(x, initial_state = hidden)
    output_b, state_h_b ,state_c_b = self.lstmb2(x,initial_state = hidden)
    print(output_f.shape)
    output_f, state_h_f ,state_c_f = self.lstm(output_f, initial_state = hidden)
    output_b, state_h_b ,state_c_b = self.lstmb(output_b,initial_state = hidden)
#    
#    
#    #output = tf.concat([output_f, output_b], axis=-1)
#    #output , state_h ,state_c, state_h ,state_c = self.Bidirectional(output_f)
#    
#    print(output_f.shape)
#    output_f, state_h_f ,state_c_f = self.lstm(output_f, initial_state = hidden)
#    output_b, state_h_b ,state_c_b = self.lstmb(output_b,initial_state = hidden)
#    
#    output_f, state_h_f, state_c_f = self.lstm(output_f, initial_state = hidden)
#    output_b, state_h_b, state_c_b = self.lstmb(output_b, initial_state = hidden)
    
    output = tf.concat([output_f, output_b], axis=-1)
    state_h = tf.concat([state_h_f, state_h_b], axis=-1)
    state_c = tf.concat([state_c_f, state_c_b], axis=-1)
    states = [state_h, state_c]
    return output, states
    

  def initialize_hidden_state(self):
    return [tf.zeros((self.batch_sz, self.enc_units)),tf.zeros((self.batch_sz, self.enc_units))]
     

#check
file_path ='large_files/glove.6B/glove.6B'
embedding_matrix = pretrained_embeddings(file_path, EMBEDDING_DIM,vocab_size, VocabInd.word2idx) 
#print('just try')
encoder = Encoder(vocab_size,EMBEDDING_DIM, units1, BATCH_SIZE,embedding_matrix )

# sample input
sample_hidden = encoder.initialize_hidden_state()
print('sample hidden',np.array(sample_hidden).shape)
sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)
print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))
#print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))
print('Encoder works well')

class Decoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz,embedding_matrix):
        super(Decoder, self).__init__()
        self.batch_sz = batch_sz
        self.dec_units = dec_units
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,
                                                        weights=[embedding_matrix]) ######
        self.embedding2 = Embedding(vocab_size, embedding_dim)#,
                                                        #weights=[embedding_matrix]) ######
        self.lstm = lstm(self.dec_units)
        self.fc = tf.keras.layers.Dense(vocab_size)
        self.fc2 = Dense(vocab_size)
        self.lstm2 = LSTM(self.dec_units,return_sequences=True, return_state=True)   #####
       
        
        # used for attention
        #self.W1 = tf.keras.layers.Dense(self.dec_units)  #############
        self.W1 = Dense(self.dec_units)
        #self.W2 = tf.keras.layers.Dense(self.dec_units)
        self.W2 = Dense(self.dec_units)
        self.V = tf.keras.layers.Dense(1)
        
    def call(self, x, hidden, enc_output):
        # enc_output shape == (batch_size, max_length, hidden_size)
        #print("output: " ,enc_output.shape)
        #print("hidden:",np.array(hidden).shape)
        # hidden shape == (batch_size, hidden size)
        # hidden_with_time_axis shape == (batch_size, 1, hidden size)
        # we are doing this to perform addition to calculate the score
        hidden_with_time_axis0 = tf.expand_dims(hidden[0], 1)
        hidden_with_time_axis1 = tf.expand_dims(hidden[1], 1)
        hidden_with_time_axis = tf.concat([hidden_with_time_axis0, hidden_with_time_axis1], axis=-1)
        #print("SHAPE: ", hidden_with_time_axis.shape)
        #print("SHAPE: ", enc_output.shape)
       
        # score shape == (batch_size, max_length, 1)
        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V
        #m=self.W2(hidden_with_time_axis)
        #print(m.shape ,"NO PRoblem")      
        #y=self.W1(enc_output)#------------------ problem here
        #print(y.shape ,"No Problem2")
        
        # score shape == (batch_size, max_length, 1)
        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V
        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))
        print(score.shape)
        print('pppppppppppppppppppppppppppppp')
        # attention_weights shape == (batch_size, max_length, 1)
        attention_weights = tf.nn.softmax(score, axis=1)
        print(attention_weights.shape)
        # context_vector shape after sum == (batch_size, hidden_size)
        context_vector = attention_weights * enc_output      ############------------
        context_vector = tf.reduce_sum(context_vector, axis=1)
        print(context_vector.shape)
        # x shape after passing through embedding == (batch_size, 1, embedding_dim)
        x = self.embedding2(x)
        print(x.shape)
        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
        
        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)
        #x = self.context_last_word_concat_layer([tf.expand_dims(context_vector, 1),x])
        print(x.shape)
        # passing the concatenated vector to the LSTM
        
        output , state_h , state_c = self.lstm2(x,hidden)  ####layer1
        #print('pass 1')
        #print(output.shape)
        output , state_h , state_c = self.lstm(output,hidden) ###layer2
        #print('pass2')
        output , state_h , state_c = self.lstm(output,hidden)###layer 3
        states = [state_h, state_c]
        
        # output shape == (batch_size * 1, hidden_size)
        output = tf.reshape(output, (-1, output.shape[2]))
        #print(output.shape)
        # output shape == (batch_size * 1, vocab)
        x = self.fc2(output)
        #print(x.shape)
        return x, states, attention_weights
        
    def initialize_hidden_state(self):
        return [
          tf.zeros((self.batch_sz, self.dec_units)),
          tf.zeros((self.batch_sz, self.dec_units))
        ]

            #####MODEL####
            
#file_path='large_files/glove.6B'
word2idx = VocabInd.word2idx
#embedding_matrix = pretrained_embeddings(file_path,Embedding_dim,vocab_size, word2idx)       
encoder = Encoder(vocab_size,EMBEDDING_DIM, units1, BATCH_SIZE,embedding_matrix )
#encoder = Encoder(vocab_size, EMBEDDING_DIM, units1, BATCH_SIZE,embedding_matrix)   #encoer model
decoder = Decoder(vocab_size,EMBEDDING_DIM, units2, BATCH_SIZE,embedding_matrix)    #decoder model with attention
#decoder = Decoder(vocab_size,200, units2, BATCH_SIZE,embedding_matrix)
"""## Define the optimizer and the loss function"""

optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-3)      #tf.train.AdamOptimizer()


def loss_function(real, pred):
  mask = 1 - np.equal(real, 0)
  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask
  return tf.reduce_mean(loss_)

"""## Checkpoints (Object-based saving)"""

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(optimizer=optimizer,
                                 encoder=encoder,
                                 decoder=decoder)

"""## Restore the latest checkpoint and test"""

# restoring the latest checkpoint in checkpoint_dir
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
###################################################################################################
################################# Training##################################################
"""## Training

1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.
2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.
3. The decoder returns the *predictions* and the *decoder hidden state*.
4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.
5. Use *teacher forcing* to decide the next input to the decoder.
6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.
7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate.
"""
##comment it ,to use for prediction
##uncomment it to completet training
EPOCHS = 10

for epoch in range(EPOCHS):
    start = time.time()
    
    hidden = encoder.initialize_hidden_state()
    total_loss = 0
    
    for (batch, (inp, targ)) in enumerate(dataset):
        loss = 0
        
        with tf.GradientTape() as tape:
          
            enc_output, enc_hidden = encoder(inp, hidden)
            
            dec_hidden = enc_hidden
            
            dec_input = tf.expand_dims([VocabInd.word2idx['<start>']] * BATCH_SIZE, 1)       
            
            # Teacher forcing - feeding the target as the next input
            for t in range(1, targ.shape[1]):
                # passing enc_output to the decoder
                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)
                
                loss += loss_function(targ[:, t], predictions)
                
                # using teacher forcing
                dec_input = tf.expand_dims(targ[:, t], 1)
        
        batch_loss = (loss / int(targ.shape[1]))
        
        total_loss += batch_loss
        
        variables = encoder.variables + decoder.variables
        
        gradients = tape.gradient(loss, variables)
        
        optimizer.apply_gradients(zip(gradients, variables))
        
        if batch % 100 == 0:
            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,
                                                         batch,
                                                         batch_loss.numpy()))
    # saving (checkpoint) the model every 2 epochs
    if (epoch + 1) % 2 == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)
    
    print('Epoch {} Loss {:.4f}'.format(epoch + 1,
                                        total_loss / N_BATCH))
    print('Time taken for 1 epoch {} sec\n'.format(time.time() - start))

#Note: The encoder output is calculated only once for one input.
########################################################################################################
########################################## prediction  ####################################
"""## Translate

* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.
* Stop predicting when the model predicts the *end token*.
* And store the *attention weights for every time step*.

Note: The encoder output is calculated only once for one input.
"""

def evaluate(sentence, encoder, decoder, VocabInd, max_length_inp, max_length_targ):
    attention_plot = np.zeros((max_length_targ, max_length_inp))
    
    sentence = preprocess_sentence(sentence)
    #print(sentence)
    
    inputs = [VocabInd.word2idx[i] for i in sentence.split(' ')]
    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')
    inputs = tf.convert_to_tensor(inputs)
    
    result = ''

    hidden = [tf.zeros((1, units1)), tf.zeros((1, units1))]   #############okayyyyyy
    enc_out, enc_hidden = encoder(inputs, hidden)

    dec_hidden = enc_hidden
    dec_input = tf.expand_dims([VocabInd.word2idx['<start>']], 0)

    for t in range(max_length_targ):
        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)
        
        # storing the attention weights to plot later on
        attention_weights = tf.reshape(attention_weights, (-1, ))
        attention_plot[t] = attention_weights.numpy()

        predicted_id = tf.argmax(predictions[0]).numpy()

        result += VocabInd.idx2word[predicted_id] + ' '

        if VocabInd.idx2word[predicted_id] == '<end>':
            return result, sentence, attention_plot
        
        # the predicted ID is fed back into the model
        dec_input = tf.expand_dims([predicted_id], 0)

    return result, sentence, attention_plot

# function for plotting the attention weights
def plot_attention(attention, sentence, predicted_sentence):
    fig = plt.figure(figsize=(10,10))
    ax = fig.add_subplot(1, 1, 1)
    ax.matshow(attention, cmap='viridis')
    
    fontdict = {'fontsize': 14}
    
    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)
    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)

    plt.show()

def Response(sentence, encoder, decoder, VocabInd, max_length_inp, max_length_targ):
    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, VocabInd, max_length_inp, max_length_targ)
        
    print('Input: {}'.format(sentence))
    print('Predicted: {}'.format(result))
    
    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]
    plot_attention(attention_plot, sentence.split(' '), result.split(' '))


Response(u'What happened in 1833?', encoder, decoder, VocabInd, max_length_inp, max_length_targ)

#Response(u'You looked beautiful last night you know', encoder, decoder, VocabInd, max_length_inp, max_length_targ)

#Response(u'Let go', encoder, decoder, VocabInd, max_length_inp, max_length_targ)

# # wrong translation
# translate(u'trata de averiguarlo.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)

"""## Next steps

* [Download a different dataset](http://www.manythings.org/anki/) to experiment with translations, for example, English to German, or English to French.
* Experiment with training on a larger dataset, or using more epochs
"""
